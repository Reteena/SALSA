{
  "experiment_name": "lexical_only_test",
  "args": {
    "train_csv": "./preprocess/lexical_features_train.csv",
    "val_csv": "./preprocess/lexical_features_test.csv",
    "test_csv": "./preprocess/lexical_features_test.csv",
    "model_type": "lexical_only",
    "acoustic_dim": 768,
    "lexical_dim": 400,
    "fusion_dim": 512,
    "num_classes": 2,
    "lora_rank": 8,
    "use_cross_attention": true,
    "aggregation_type": "attention",
    "dropout": 0.1,
    "batch_size": 16,
    "max_epochs": 5,
    "learning_rate": 0.0001,
    "weight_decay": 1e-05,
    "patience": 3,
    "min_delta": 0.001,
    "loss_type": "focal",
    "focal_alpha": 1.0,
    "focal_gamma": 2.0,
    "label_smoothing": 0.05,
    "use_class_weights": false,
    "use_group_dro": false,
    "num_groups": 2,
    "group_weights_lr": 0.01,
    "max_utterances_per_recording": 100,
    "normalize_features": true,
    "filter_min_utterances": 1,
    "num_workers": 4,
    "device": "auto",
    "seed": 42,
    "experiment_name": "lexical_only_test",
    "output_dir": "./experiments",
    "save_model": true
  },
  "best_val_f1": 0.7290490664350847,
  "test_metrics": {
    "accuracy": 0.7291666666666666,
    "balanced_accuracy": 0.7291666666666667,
    "macro_f1": 0.7290490664350847,
    "weighted_f1": 0.7290490664350848,
    "precision": 0.7295652173913043,
    "recall": 0.7291666666666667,
    "auroc": 0.7291666666666666,
    "auprc": 0.6693840579710144,
    "f1_healthy": 0.7346938775510204,
    "f1_dementia": 0.723404255319149,
    "ece": 0.2704347826086957,
    "brier_score": 0.2708333333333333,
    "mce": 0.28
  },
  "model_params": {
    "total": 765571,
    "trainable": 765571
  }
}