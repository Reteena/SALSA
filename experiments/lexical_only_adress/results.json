{
  "experiment_name": "lexical_only_adress",
  "args": {
    "train_csv": "./preprocess/lexical_features_train.csv",
    "val_csv": "./preprocess/lexical_features_test.csv",
    "test_csv": "./preprocess/lexical_features_test.csv",
    "model_type": "lexical_only",
    "acoustic_dim": 768,
    "lexical_dim": 400,
    "fusion_dim": 512,
    "num_classes": 2,
    "lora_rank": 8,
    "use_cross_attention": true,
    "aggregation_type": "attention",
    "dropout": 0.1,
    "batch_size": 16,
    "max_epochs": 50,
    "learning_rate": 0.0001,
    "weight_decay": 1e-05,
    "patience": 10,
    "min_delta": 0.001,
    "loss_type": "focal",
    "focal_alpha": 1.0,
    "focal_gamma": 2.0,
    "label_smoothing": 0.05,
    "use_class_weights": false,
    "use_group_dro": false,
    "num_groups": 2,
    "group_weights_lr": 0.01,
    "max_utterances_per_recording": 100,
    "normalize_features": true,
    "filter_min_utterances": 1,
    "num_workers": 4,
    "device": "auto",
    "seed": 42,
    "experiment_name": "lexical_only_adress",
    "output_dir": "./experiments",
    "save_model": true
  },
  "best_val_f1": 0.7699346405228757,
  "test_metrics": {
    "accuracy": 0.7708333333333334,
    "balanced_accuracy": 0.7708333333333334,
    "macro_f1": 0.7699346405228757,
    "weighted_f1": 0.7699346405228757,
    "precision": 0.7751322751322751,
    "recall": 0.7708333333333334,
    "auroc": 0.7708333333333335,
    "auprc": 0.7192460317460319,
    "f1_healthy": 0.7843137254901961,
    "f1_dementia": 0.7555555555555555,
    "ece": 0.22486772486772486,
    "brier_score": 0.22916666666666666,
    "mce": 0.25925925925925924
  },
  "model_params": {
    "total": 765571,
    "trainable": 765571
  }
}